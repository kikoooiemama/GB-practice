{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0987b5c8",
   "metadata": {},
   "source": [
    "# Практическое задание №9 по теме \" Трансформер\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a98752",
   "metadata": {},
   "source": [
    "1. Возьмите готовую модель из https://huggingface.co/models для классификации сентимента текста.\n",
    "2. Сделайте предсказания на всем df_val. Посчитайте метрику качества.\n",
    "3. Дообучите эту модель на df_train. Посчитайте метрику качества на df_val.\n",
    "\n",
    "Данные на google drive: https://drive.google.com/file/d/1Mev_EEput0LlBj8MDHIJkBtahlJ6J901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3a4518",
   "metadata": {
    "id": "mn3NT9WttbV2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aab62d",
   "metadata": {
    "id": "pAu_x1oWPDCU"
   },
   "source": [
    "В качестве готовой модели была взята модель \"Tatyana/rubert-base-cased-sentiment-new\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f810a72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2slkmaCqtdeM",
    "outputId": "fb512d60-98de-47ef-f401-9cbe36e50964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9541073441505432}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment = pipeline(\"text-classification\", model='Tatyana/rubert-base-cased-sentiment-new')\n",
    "sentiment(\"Этот ресторан отличный\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406803cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0XCBc2BtdgO",
    "outputId": "6cac3aa2-5a79-4444-ab4a-973ba2f33117"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((181467, 3), (22683, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "val_df = pd.read_csv(\"data/val.csv\")\n",
    "\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d623f80c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Y_6wiM9GtdiR",
    "outputId": "203b74f0-f4b1-49bf-cfbd-164d9648d830"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "354a5ac8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3JbGuLPtdkr",
    "outputId": "a3054958-4e6c-413a-8373-f691d527ca7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    92063\n",
       "0    89404\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fb7dff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qxc0213NuvwX",
    "outputId": "6dd182a5-72ad-4fdc-a76e-5b4a43455800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мартовские путёвки дорожают на глазах. только пару дней назад были за 66, уже 86 о_О\n",
      "label is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9948994517326355}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 11\n",
    "print(train_df.iloc[idx]['text'])\n",
    "print('label is', train_df.iloc[idx]['class'])\n",
    "sentiment(train_df.iloc[idx]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e55848a6",
   "metadata": {
    "id": "mfXRF2I_uvyj"
   },
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].apply(lambda x: x.lower())\n",
    "val_df['text'] = val_df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95920819",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVwWIxTvuv06",
    "outputId": "dbe04d20-84d7-4d90-9fea-82b9856f1223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 17863, 10316,   949, 15427,   831,  2703,   102,     0,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('Tatyana/rubert-base-cased-sentiment-new')\n",
    "\n",
    "example_text = 'Пример текста для токенизации'\n",
    "bert_input = tokenizer(example_text, padding='max_length', max_length=10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e09c965",
   "metadata": {
    "id": "SuQlnqK-uv79"
   },
   "outputs": [],
   "source": [
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, txts, labels):\n",
    "        self._labels = labels\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained('Tatyana/rubert-base-cased-sentiment-new')\n",
    "        self._txts = [self.tokenizer(text, padding='max_length', max_length=10,\n",
    "                                     truncation=True, return_tensors=\"pt\")\n",
    "                      for text in txts]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._txts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self._txts[index], self._labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124bb8b1",
   "metadata": {
    "id": "qLRGNvy4uv9-"
   },
   "outputs": [],
   "source": [
    "y_train = train_df['class'].values\n",
    "y_val = val_df['class'].values\n",
    "\n",
    "train_dataset = TwitterDataset(train_df['text'], y_train)\n",
    "valid_dataset = TwitterDataset(val_df['text'], y_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                          batch_size=64,\n",
    "                          shuffle=False,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23fc8827",
   "metadata": {
    "id": "FGq35BdzvbSm"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('Tatyana/rubert-base-cased-sentiment-new')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \n",
    "        _, pooled_output = self.bert(input_ids=x, attention_mask=mask, return_dict=False)\n",
    "        # _, pooled_output - набор эмбеддинигов слов, эмбеддинг предложения\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.sigm(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49d4ac27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "PwEN7ZQdvbUr",
    "outputId": "bf9ce319-4e3f-4b9d-dc4f-267c0e070827"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c7bdf85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "URRLJLrlvbW4",
    "outputId": "93c3decf-a1ba-46a4-e1e9-e56fe8533989"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Tatyana/rubert-base-cased-sentiment-new were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.linear.parameters(), lr=0.001)  # неполное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e12f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61104b76",
   "metadata": {
    "id": "fh6_K9i8Kkey"
   },
   "source": [
    "Получение метрик на валидационной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd36fd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDAjAeKKwEAv",
    "outputId": "83ae7ce2-d0fa-4e25-e9e5-feb1de484c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 |          | Val Loss:  0.011         | Val Accuracy:  0.505\n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(1):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "            \n",
    "    model.eval()\n",
    "    total_loss_val, total_acc_val = 0.0, 0.0\n",
    "    for val_input, val_label in valid_loader:\n",
    "        val_label = val_label.to(device)\n",
    "        mask = val_input['attention_mask'].to(device)\n",
    "        input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "\n",
    "        batch_loss = criterion(output, val_label)\n",
    "        total_loss_val += batch_loss.item()\n",
    "                    \n",
    "        acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "        total_acc_val += acc\n",
    "            \n",
    "    print(\n",
    "        f'Epochs: {epoch_num + 1} |  \\\n",
    "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
    "        | Val Accuracy: {total_acc_val / len(valid_dataset): .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e393649d",
   "metadata": {
    "id": "dBjGYh1dKqP-"
   },
   "source": [
    "Дообучение модели и получение метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74161596",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0nAZePf0wECr",
    "outputId": "c594025e-3feb-498f-deda-d21138403feb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2836/2836 [05:19<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.010         | Train Accuracy:  0.587         | Val Loss:  0.010         | Val Accuracy:  0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2836/2836 [05:18<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.010         | Train Accuracy:  0.587         | Val Loss:  0.010         | Val Accuracy:  0.585\n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(epochs):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    model.train()\n",
    "    for train_input, train_label in tqdm(train_loader):\n",
    "        mask = train_input['attention_mask'].to(device)\n",
    "        input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        train_label = train_label.to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "                \n",
    "        batch_loss = criterion(output, train_label)\n",
    "        total_loss_train += batch_loss.item()\n",
    "                \n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        total_acc_train += acc\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    model.eval()\n",
    "    total_loss_val, total_acc_val = 0.0, 0.0\n",
    "    for val_input, val_label in valid_loader:\n",
    "        val_label = val_label.to(device)\n",
    "        mask = val_input['attention_mask'].to(device)\n",
    "        input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "\n",
    "        batch_loss = criterion(output, val_label)\n",
    "        total_loss_val += batch_loss.item()\n",
    "                    \n",
    "        acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "        total_acc_val += acc\n",
    "            \n",
    "    print(\n",
    "        f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
    "        | Train Accuracy: {total_acc_train / len(train_dataset): .3f} \\\n",
    "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
    "        | Val Accuracy: {total_acc_val / len(valid_dataset): .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a446751",
   "metadata": {
    "id": "Z6RnhJO1Oa31"
   },
   "source": [
    "Как видно из метрик, дообученная модель имеет более лучшие показатели Val Loss и Val Accuracy, качество которых с увеличением эпох, вероятно, будет расти."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa8b88",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
